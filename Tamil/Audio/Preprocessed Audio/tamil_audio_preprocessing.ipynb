{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1tsbEhy3oaOzeRc3315eoWeFjW0Dsfh9Q","authorship_tag":"ABX9TyN2PdfC3IqAZRNaDLrwzoC9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install numpy scipy pydub noisereduce librosa soundfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSACcRRoBSGY","executionInfo":{"status":"ok","timestamp":1736442844473,"user_tz":-330,"elapsed":4491,"user":{"displayName":"SHRI SASHMITHA S 22ADR100","userId":"17950867024027937145"}},"outputId":"f1e656ce-d7d4-4ea9-a7c7-ca76824913fd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting noisereduce\n","  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.13.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.67.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.4.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n","Installing collected packages: pydub, noisereduce\n","Successfully installed noisereduce-3.0.3 pydub-0.25.1\n"]}]},{"cell_type":"code","source":["import os\n","import zipfile\n","import shutil\n","import librosa\n","import numpy as np\n","import soundfile as sf\n","from sklearn.utils import resample\n","from noisereduce import reduce_noise\n","import pandas as pd\n","\n","# Function to unzip files\n","def unzip_file(zip_file, extract_to):\n","    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)\n","\n","# Advanced audio preprocessing\n","def preprocess_audio(file_path, output_path, sample_rate=16000, target_duration=3.0):\n","    y, sr = librosa.load(file_path, sr=None)\n","\n","    # Noise reduction\n","    reduced_noise = reduce_noise(y=y, sr=sr, prop_decrease=0.8)\n","\n","    # Resample to standard sample rate\n","    if sr != sample_rate:\n","        y = librosa.resample(reduced_noise, orig_sr=sr, target_sr=sample_rate)\n","    else:\n","        y = reduced_noise\n","\n","    # Trimming and silence removal\n","    y, _ = librosa.effects.trim(y, top_db=20)\n","\n","    # Amplitude normalization\n","    y = librosa.util.normalize(y)\n","\n","    # Handling variable lengths\n","    target_length = int(sample_rate * target_duration)\n","    if len(y) < target_length:\n","        y = np.pad(y, (0, target_length - len(y)), mode='constant')\n","    else:\n","        y = y[:target_length]\n","\n","    # Save preprocessed audio\n","    sf.write(output_path, y, sample_rate)\n","\n","# Classify audio files based on file name\n","def classify_audio(file_name):\n","    if file_name.startswith(\"H\"):\n","        main_class = \"Hate\"\n","        subclass = None\n","        if \"_G_\" in file_name:\n","            subclass = \"Gender\"\n","        elif \"_P_\" in file_name:\n","            subclass = \"Political\"\n","        elif \"_R_\" in file_name:\n","            subclass = \"Religious\"\n","        elif \"_C_\" in file_name:\n","            subclass = \"Personal Defamation\"\n","    elif file_name.startswith(\"NH\"):\n","        main_class = \"Not Hate\"\n","        subclass = None\n","    else:\n","        main_class = \"Unknown\"\n","        subclass = None\n","    return main_class, subclass\n","\n","# Balance dataset by oversampling\n","def balance_subclasses_and_not_hate(hate_data, not_hate_data, target_count_per_subclass, target_count_not_hate):\n","    balanced_hate_data = []\n","\n","    # Balance each subclass of \"Hate\"\n","    for subclass in hate_data[\"subclass\"].unique():\n","        subset = hate_data[hate_data[\"subclass\"] == subclass]\n","        if len(subset) < target_count_per_subclass:\n","            oversampled = resample(subset, replace=True, n_samples=target_count_per_subclass, random_state=42)\n","            balanced_hate_data.append(oversampled)\n","        else:\n","            balanced_hate_data.append(subset)\n","\n","    # Concatenate all balanced subclasses\n","    balanced_hate_df = pd.concat(balanced_hate_data)\n","\n","    # Balance \"Not Hate\" to match total \"Hate\" records\n","    if len(not_hate_data) < target_count_not_hate:\n","        balanced_not_hate_df = resample(not_hate_data, replace=True, n_samples=target_count_not_hate, random_state=42)\n","    else:\n","        balanced_not_hate_df = not_hate_data\n","\n","    return pd.concat([balanced_hate_df, balanced_not_hate_df])\n","\n","# Process audio files and collect metadata\n","def process_audio_files(input_folder, output_folder, sample_rate=16000, target_duration=3.0):\n","    os.makedirs(output_folder, exist_ok=True)\n","    metadata = []\n","    for file_name in os.listdir(input_folder):\n","        if file_name.endswith('.wav'):\n","            file_path = os.path.join(input_folder, file_name)\n","            output_path = os.path.join(output_folder, file_name)\n","\n","            preprocess_audio(file_path, output_path, sample_rate, target_duration)\n","\n","            # Classify the file\n","            main_class, subclass = classify_audio(file_name)\n","            metadata.append({\"file_name\": file_name, \"label\": main_class, \"subclass\": subclass, \"path\": output_path})\n","\n","    return pd.DataFrame(metadata)\n","\n","# Zip folder\n","def create_zip(folder_path, zip_name):\n","    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","        for root, _, files in os.walk(folder_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                arcname = os.path.relpath(file_path, folder_path)\n","                zipf.write(file_path, arcname)\n","\n","# Display record counts\n","def display_record_counts(metadata_df):\n","    # Count records per class and subclass\n","    class_counts = metadata_df.groupby(\"label\").size()\n","    print(\"Number of records per class:\")\n","    print(class_counts)\n","\n","    # Count records per subclass within \"Hate\"\n","    hate_subclass_counts = metadata_df[metadata_df[\"label\"] == \"Hate\"].groupby(\"subclass\").size()\n","    print(\"\\nNumber of records per subclass within 'Hate':\")\n","    print(hate_subclass_counts)\n","\n","# Main workflow\n","zip_file = \"/content/drive/MyDrive/Dravidian-2025/Tamil/Audio/Raw/audio_ta_train.zip\"\n","extract_to = \"extracted_files\"\n","output_folder = \"preprocessed_audio\"\n","final_output_folder = \"final_dataset\"\n","output_zip = \"/content/drive/MyDrive/tamil_train_audio_preprocessed4.zip\"\n","\n","# Step 1: Unzip files\n","unzip_file(zip_file, extract_to)\n","\n","# Step 2: Preprocess files and collect metadata\n","metadata_df = process_audio_files(f\"{extract_to}/audio\", output_folder)\n","\n","# Step 3: Separate data by label and subclass\n","hate_data = metadata_df[metadata_df[\"label\"] == \"Hate\"]\n","not_hate_data = metadata_df[metadata_df[\"label\"] == \"Not Hate\"]\n","\n","# Debug: Print counts before balancing\n","print(f\"Hate data records: {len(hate_data)}\")\n","print(f\"Not Hate data records: {len(not_hate_data)}\")\n","\n","# Step 4: Balance the data\n","target_count_per_subclass = 122  # Target number of records per subclass in Hate\n","target_count_not_hate = 122 * 4  # Target total for Not Hate, matching total Hate count\n","\n","final_metadata_df = balance_subclasses_and_not_hate(hate_data, not_hate_data, target_count_per_subclass, target_count_not_hate)\n","\n","# Debug: Check if final_metadata_df is created successfully\n","if final_metadata_df is not None:\n","    print(\"Final metadata DataFrame created successfully.\")\n","else:\n","    print(\"Error: Final metadata DataFrame is None.\")\n","\n","# Display record counts\n","display_record_counts(final_metadata_df)\n","\n","# Step 5: Save final dataset and zip\n","shutil.rmtree(final_output_folder, ignore_errors=True)\n","os.makedirs(final_output_folder, exist_ok=True)\n","\n","for _, row in final_metadata_df.iterrows():\n","    shutil.copy(row[\"path\"], os.path.join(final_output_folder, row[\"file_name\"]))\n","\n","create_zip(final_output_folder, output_zip)\n","\n","print(f\"Preprocessed and balanced audio dataset saved at {output_zip}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpqeTFidDv_G","executionInfo":{"status":"ok","timestamp":1736443298103,"user_tz":-330,"elapsed":294638,"user":{"displayName":"SHRI SASHMITHA S 22ADR100","userId":"17950867024027937145"}},"outputId":"3892541e-9621-46c8-d962-9669f2f25a1f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Hate data records: 222\n","Not Hate data records: 287\n","Final metadata DataFrame created successfully.\n","Number of records per class:\n","label\n","Hate        488\n","Not Hate    488\n","dtype: int64\n","\n","Number of records per subclass within 'Hate':\n","subclass\n","Gender                 122\n","Personal Defamation    122\n","Political              122\n","Religious              122\n","dtype: int64\n","Preprocessed and balanced audio dataset saved at /content/drive/MyDrive/tamil_train_audio_preprocessed4.zip.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KmTDx-cCEXqU"},"execution_count":null,"outputs":[]}]}