{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1C9w5EgUG850_0Ftm6nSkvVYSsLDzl8kv","authorship_tag":"ABX9TyOoK+kBdnpH5B/G8aMzfTyl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import re\n","import pandas as pd\n","import nltk\n","from sklearn.utils import resample\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","\n","# File paths\n","file_path = '/content/drive/MyDrive/ML-AT-train.xlsx'\n","test_file_path = '/content/drive/MyDrive/ML-AT-test.xlsx'\n","\n","# Load training data\n","data = pd.read_excel(file_path)\n","\n","# Preprocessing Malayalam text\n","def preprocess_malayalam_text(text):\n","    # Step 1: Normalize Unicode\n","    text = re.sub(r'\\u200c', '', text)  # Remove Zero-Width Non-Joiner (ZWNJ) if present\n","\n","    # Step 2: Remove non-Malayalam characters, special characters, and numbers\n","    text = re.sub(r'[^\\u0D00-\\u0D7F\\s]', '', text)  # Retain only Malayalam script and spaces\n","    text = re.sub(r'\\d+', '', text)  # Remove numeric values\n","\n","    # Step 3: Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    # Step 4: Handle commonly used spoken variants (expanded replacements)\n","    replacements = {\n","        \"ഏ\": \"എ\",  # Normalize vowels\n","        \"ഓ\": \"ഒ\",\n","        \"കൌ\": \"കോ\",  # Normalize common diphthongs\n","        \"ചൌ\": \"ചോ\",\n","        \"പൌ\": \"പോ\",\n","        \"കെ\": \"കേ\",\n","        \"ചെ\": \"ചേ\",\n","        \"ടെ\": \"ടേ\",\n","        \"തെ\": \"തേ\",\n","        \"നെ\": \"നേ\",\n","        \"പെ\": \"പേ\",\n","        \"മെ\": \"മേ\",\n","        \"വെ\": \"വേ\",\n","        \"ലെ\": \"ലേ\",\n","        \"റ്റെ\": \"റ്റേ\",\n","        \"ണെ\": \"ണേ\",\n","        \"ഇ\": \"എ\",  # Normalize short vowels\n","        \"ഉ\": \"ഒ\",\n","        \"ക്ഷ\": \"ക\",  # Normalize compound consonants\n","        \"ജ\": \"ച\"\n","    }\n","    for key, value in replacements.items():\n","        text = text.replace(key, value)\n","\n","    return text\n","\n","# Tokenize Malayalam text using NLTK\n","def tokenize_text(text):\n","    # Tokenize the text using NLTK\n","    tokens = nltk.word_tokenize(text)\n","    return ' '.join(tokens)\n","\n","# Apply preprocessing and tokenization to the data\n","data['Transcript'] = data['Transcript'].apply(preprocess_malayalam_text)\n","data['Transcript'] = data['Transcript'].apply(tokenize_text)\n","\n","# Remove LabelEncoder and keep the 'Class Label Short' as is (no numeric encoding)\n","# No transformation of labels is needed anymore\n","# Now, we will use 'Class Label Short' as the label\n","\n","# Upsample the data to balance class distribution\n","class_counts = data['Class Label Short'].value_counts()\n","max_class_size = class_counts.max()\n","upsampled_data = []\n","\n","for label in class_counts.index:\n","    class_data = data[data['Class Label Short'] == label]\n","    # Upsample to the maximum class size\n","    upsampled_class_data = resample(class_data, replace=True, n_samples=max_class_size, random_state=42)\n","    upsampled_data.append(upsampled_class_data)\n","\n","balanced_data = pd.concat(upsampled_data)\n","balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Save the preprocessed training data\n","dataset = balanced_data[[\"Transcript\", \"Class Label Short\"]]\n","dataset.columns = [\"Text\", \"Label\"]\n","dataset.to_csv('/content/drive/MyDrive/processed_train_data.csv', index=False)\n","\n","# Load and preprocess test data\n","test_data = pd.read_excel(test_file_path)\n","test_data['Transcript'] = test_data['Transcript'].apply(preprocess_malayalam_text)\n","test_data['Transcript'] = test_data['Transcript'].apply(tokenize_text)\n","\n","# Save the preprocessed test data\n","dataset_t = test_data[[\"Transcript\"]]\n","dataset_t.to_csv('/content/drive/MyDrive/processed_test_data.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhmoT8T5Im4V","executionInfo":{"status":"ok","timestamp":1735140589928,"user_tz":-330,"elapsed":13871,"user":{"displayName":"SHRI SASHMITHA S 22ADR100","userId":"17950867024027937145"}},"outputId":"92f69873-6c74-4ac5-f7d5-28d1c967416e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JB6Dvfj5JQYm"},"execution_count":null,"outputs":[]}]}